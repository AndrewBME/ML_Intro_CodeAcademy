# ML Intro -- CodeAcademy


Introduction to Machine Learning from Code Academy. Coded by Andrew Chen, instructed by Code Academy. Open source just for learning. Happy coding!

#### Note 
This just offers the code of a toddler (at least Andrew is still a todeler now). Please make sure to set up your environment, install required packages to start the journey! 

## Bayes' Theorem 
To be short, [Bayes' Theorem](https://en.wikipedia.org/wiki/Bayes%27_theorem) can be used to describe the probability of a hypothesis of a given hypothesis. It can be the capestone of machine learing.

Formula: P(H|D) = P(D|H)*P(H)/P(D) 

The Bayes' Theorem introduced here is majorly Naive Bayes Classifier. The datasets are independent of another. 

In the project, you will learn how to make a email spam with Naive Bayes Classifer. 

(But I did not store the code, so it is not here sorry about that)

## Decision Tree
[Decision Tree](https://en.wikipedia.org/wiki/Decision_tree) is an algorithm involves both classification and regression. Just like tree in real life, the tree began to develop from a root and develop different branches, as knwon as nodes. Since this method may require to try all possible results, it is also called ["greedy algorithm"](https://en.wikipedia.org/wiki/Greedy_algorithm).

However, relentless iteration is a waste of cmputation. So the programmer needs to determine when to stop splitting a tree. You can either set the minimum input or the maximum output of your tree. 

Unfortunately, I forgot to save this file too. So please refer to online resources. Like this: [Decision Tree in Machine Learning](https://towardsdatascience.com/decision-trees-in-machine-learning-641b9c4e8052)


## Perceptron 
Different from the definition in biology, [Perceptron](https://en.wikipedia.org/wiki/Perceptron) here means an algorithm which applies linear function top classify different objects. 

In this repo ["Perceptron.py"](https://github.com/AndrewBME/ML_Intro_CodeAcademy/blob/master/Perceptron/Perceptron.py),you will knwo how to make a classifier with perceptron. First, we will build a class "Perceptron". Then, we would take into different inputs. Next, we would train this perceptron with random inputs. Don't forget, we need to calculate bias weight according to te weights of data, too! 

Time to enjoy Perceptron!
## Random Forest 

## Unsupervised Learning 

